{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import uniform\n",
    "from math import exp, log\n",
    "from collections import OrderedDict\n",
    "from pprint import pprint\n",
    "\n",
    "# Plot settings\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспомогательные функции для генерации данных:\n",
    "def generate_moons(n_samples=200, noise=0.2, visualize=True):\n",
    "    X, y = sklearn.datasets.make_moons(n_samples, noise=noise)\n",
    "    if visualize:\n",
    "        plt.scatter(X[:,0], X[:,1], s=40, c=y, cmap=plt.cm.Spectral)\n",
    "    return X, y\n",
    "\n",
    "def get_random_number(a=-1, b=1):\n",
    "    return uniform(a, b)\n",
    "\n",
    "# Функции активации и их производные:\n",
    "def ReLU(x, return_derivative=False):\n",
    "    if not return_derivative:\n",
    "        return max(0, x)\n",
    "    else:\n",
    "        return (x > 0) * 1\n",
    "\n",
    "def softplus(x, return_derivative=False, limit=30):\n",
    "    if not return_derivative:\n",
    "        if x > limit:\n",
    "            return x\n",
    "        else:\n",
    "            return log(1 + exp(x))\n",
    "    else:\n",
    "        return sigmoid(x)\n",
    "\n",
    "def sigmoid(x, return_derivative=False):\n",
    "    if not return_derivative:\n",
    "        try:\n",
    "            res = 1 / (1 + exp(-x))\n",
    "        except OverflowError:\n",
    "            res = 0\n",
    "    else:\n",
    "        res = sigmoid(x) * (1 - sigmoid(x))\n",
    "    return res\n",
    "\n",
    "def log_loss(y, p, return_derivative=False):\n",
    "    if not return_derivative:\n",
    "        try:\n",
    "            logarithm_p = log(p)\n",
    "        except ValueError:\n",
    "            logarithm_p = -744\n",
    "        try:\n",
    "            logarithm_1_p = log(1-p)\n",
    "        except ValueError:\n",
    "            logarithm_1_p = -744\n",
    "        return -(y*logarithm_p + (1-y)*logarithm_1_p)\n",
    "    else:\n",
    "        return -((y - p) / (p * (1 - p))) * (p * (1 - p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedConnection:\n",
    "    ### Класс для описания связей между нейронами.\n",
    "    # Содержит: вес связи, входной и выходной нейрон,\n",
    "    # обновленный вес после прямого прохода нейронной сети,\n",
    "    # значения антиградиента (для подсчета обратного распространения ошибки).\n",
    "\n",
    "    def __init__(self, weight=None, input_neuron=None, output_neuron=None):\n",
    "        if weight is None:\n",
    "            weight = get_random_number(0, 1)\n",
    "        self.weight = weight\n",
    "        self.input_neuron = input_neuron\n",
    "        self.output_neuron = output_neuron\n",
    "\n",
    "        self.updated_weight = None\n",
    "        self.anti_gradient = None\n",
    "        \n",
    "    def send_signal_through_connection(self, signal):\n",
    "        if not self.input_neuron or not self.output_neuron:\n",
    "            print('Cannot send signal, because '\n",
    "                  'there is no input/output connection')\n",
    "            return False\n",
    "        self.output_neuron.receive_new_input_signal_from(self, signal*self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    ### Класс для описания нейронов.\n",
    "    # Содержит: функцию активации нейрона,\n",
    "    # последнее значение функции активации (от взешенной суммы значений всех входных связей),\n",
    "    # bias и обновленный bias после прямого прохода нейронной сети,\n",
    "    # значения антиградиента (для подсчета обратного распространения ошибки),\n",
    "    # словарь всех входных связей нейрона (со взешенными значениями),\n",
    "    # множество входных связей, от которых получены сигналы (для проверки готовности активации нейрона),\n",
    "    # множество всех выходных связей нейрона.\n",
    "    instance_counter = 0\n",
    "\n",
    "    def __init__(self, activation_function=ReLU):\n",
    "        Neuron.instance_counter += 1\n",
    "        self.name = str(Neuron.instance_counter) \n",
    "        self.activation_function = activation_function\n",
    "        self.last_value = None\n",
    "        self.bias = 0\n",
    "        self.updated_bias = None\n",
    "        # input_connection = {WeightedConnection(): input_value}\n",
    "        self.input_connections = OrderedDict()\n",
    "        self.received_signals_from = set()\n",
    "\n",
    "        # output_connection = set(WeightedConnection())\n",
    "        self.output_connections = set()\n",
    "\n",
    "    def create_output_connection_with(self, neuron, weight=None, input_value=None):\n",
    "        new_neuron_connection = WeightedConnection(weight=weight,\n",
    "                                                   input_neuron=self,\n",
    "                                                   output_neuron=neuron)\n",
    "        self.output_connections.add(new_neuron_connection)\n",
    "        neuron.input_connections[new_neuron_connection] = input_value\n",
    "        return True\n",
    "\n",
    "    def receive_new_input_signal_from(self, connection, weighted_signal):\n",
    "        if connection not in self.input_connections:\n",
    "            print('Cannot receive new input signal, because no such input neuron')\n",
    "            return False\n",
    "        self.input_connections[connection] = weighted_signal\n",
    "        self.received_signals_from.add(connection)\n",
    "        return True\n",
    "\n",
    "    def has_received_signals_from_all_connections(self):\n",
    "        if self.is_input_neuron():\n",
    "            if self.last_value is None:\n",
    "                return False\n",
    "        elif self.is_middle_neuron() or self.is_output_neuron():\n",
    "            if (not self.input_connections) or \\\n",
    "                (not self.received_signals_from) or \\\n",
    "                 (len(self.input_connections) != len(self.received_signals_from)):\n",
    "                return False\n",
    "        else:\n",
    "            print('Cannot determine neuron type')\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def activate(self):\n",
    "        # Проверяем, можем ли активировать данный тип нейрона:\n",
    "        if self.is_input_neuron():\n",
    "            if len(self.output_connections) == 0:\n",
    "                print(\"Cannot activate input neuron, \"\n",
    "                      \"because it has no output connecitons\")\n",
    "                return False\n",
    "        elif self.is_output_neuron():\n",
    "            if (len(self.input_connections) == 0) or \\\n",
    "                    (not self.has_received_signals_from_all_connections()):\n",
    "                print(\"Cannot activate output neuron, \"\n",
    "                      \"because it has no input connecitons\")\n",
    "                return False\n",
    "        elif self.is_middle_neuron():\n",
    "            if (None in self.input_connections.values()) or \\\n",
    "                   (not self.has_received_signals_from_all_connections()):\n",
    "                print(\"Cannot activate neuron, \"\n",
    "                      \"because it hasn't received all signals \"\n",
    "                      \"from each input neuron yet\")\n",
    "                return False\n",
    "        else:\n",
    "            print('Cannot determine neuron type')\n",
    "            return False\n",
    "        # calculate activated input signal\n",
    "        input_signal = 0\n",
    "        if self.is_input_neuron():\n",
    "            if self.last_value is None:\n",
    "                print(\"Cannot activate input neuron, \"\n",
    "                      \"because its last value is empty\")\n",
    "                return False\n",
    "            input_signal = self.last_value\n",
    "        else:\n",
    "            for input_connection, input_value in self.input_connections.items():\n",
    "                input_signal += input_value\n",
    "        self.last_value = self.activation_function(input_signal + self.bias)\n",
    "\n",
    "        # send signal through each output conneciton\n",
    "        for output_connection in self.output_connections:\n",
    "            output_connection.send_signal_through_connection(self.last_value)\n",
    "\n",
    "        # ready to receive new signals\n",
    "        self.received_signals_from = set()\n",
    "        return True\n",
    "\n",
    "    def calculate_anti_gradient(self):\n",
    "        if self.is_input_neuron():\n",
    "            if len(self.output_connections) == 0:\n",
    "                print(\"Cannot calculate anti-gradient, \"\n",
    "                      \"because neuron has no output connecitons\")\n",
    "                return None\n",
    "        elif self.is_output_neuron():\n",
    "            print(\"For calculation of output neuron anti-gradient \"\n",
    "                  \"use cost function derivative\")\n",
    "            return None\n",
    "        elif self.is_middle_neuron():\n",
    "            if None in self.input_connections.values():\n",
    "                print(\"Cannot calculate anti-gradient, \"\n",
    "                      \"because neuron hasn't received all signals \"\n",
    "                      \"from each input neuron yet\")\n",
    "                return None\n",
    "        else:\n",
    "            print('Cannot determine neuron type')\n",
    "            return None\n",
    "        # calculate activated output signal\n",
    "        anti_gradient = 0\n",
    "        for output_connection in self.output_connections:\n",
    "            if output_connection.anti_gradient is None:\n",
    "                print(\"Cannot calculate neuron anti-gradient, \"\n",
    "                      \"because there is 'None' in \"\n",
    "                      \"one of neurons output connections\")\n",
    "                return None\n",
    "            anti_gradient += output_connection.anti_gradient\n",
    "        return anti_gradient\n",
    "\n",
    "    def is_input_neuron(self):\n",
    "        if len(self.input_connections) == 0 and len(self.output_connections) > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def is_middle_neuron(self):\n",
    "        if len(self.input_connections) > 0 and len(self.output_connections) > 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def is_output_neuron(self):\n",
    "        if len(self.input_connections) > 0 and len(self.output_connections) == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedNeuroNetwork:\n",
    "    ### Класс для описания полносвязной нейронной сети.\n",
    "    # Содержит: функцию потерь,\n",
    "    # learning_rate - скорость обучения,\n",
    "    # derivative_delta - константа для числовой проверки вычисленной производной.\n",
    "\n",
    "    def __init__(self, cost_function=log_loss, learning_rate=0.01):\n",
    "        self.layers = []\n",
    "        self.cost_function = cost_function\n",
    "        self.learning_rate = learning_rate\n",
    "        self.derivative_delta = 0.001\n",
    "        self.ready_to_back_propagate = False\n",
    "        Neuron.instance_counter = 0\n",
    "    \n",
    "    def add_layer(self, number_of_neurons, activation_function=ReLU):\n",
    "        if len(self.layers) == 0:\n",
    "            if not self.add_input_layer(number_of_neurons, activation_function):\n",
    "                return False\n",
    "        else:\n",
    "            if not self.add_fully_connected_layer(number_of_neurons, activation_function):\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "    def add_input_layer(self, number_of_neurons, activation_function=ReLU):\n",
    "        if len(self.layers) > 0:\n",
    "            print('Cannot add input layer, because it is already exists')\n",
    "            return False\n",
    "        else:\n",
    "            new_neuron_layer = tuple(\n",
    "                Neuron(activation_function=activation_function) \\\n",
    "                    for neuron in range(number_of_neurons)\n",
    "            )\n",
    "            self.layers.append(new_neuron_layer)\n",
    "            return True\n",
    "        \n",
    "    def add_fully_connected_layer(self, number_of_neurons, activation_function=ReLU):\n",
    "        if len(self.layers) > 0:\n",
    "            new_neuron_layer = tuple(\n",
    "                Neuron(activation_function=activation_function) \\\n",
    "                    for neuron in range(number_of_neurons)\n",
    "            )\n",
    "            previous_layer = self.layers[-1]\n",
    "            for output_neuron in previous_layer:\n",
    "                for input_neuron in new_neuron_layer:\n",
    "                    output_neuron.create_output_connection_with(input_neuron)\n",
    "            self.layers.append(new_neuron_layer)\n",
    "            return True\n",
    "        else:\n",
    "            print('Cannot add fully_connected layer, because neural network is empty')\n",
    "            return False\n",
    "        \n",
    "    def get_input_layer(self):\n",
    "        if len(self.layers) > 0:\n",
    "            return self.layers[0]\n",
    "        else:\n",
    "            print('Cannot get input layer, because neural network is empty')\n",
    "            return None\n",
    "        \n",
    "    def get_output_layer(self):\n",
    "        if len(self.layers) > 0:\n",
    "            return self.layers[-1]\n",
    "        else:\n",
    "            print('Cannot get output layer, because neural network is empty')\n",
    "            return None\n",
    "\n",
    "    def is_input_layer(self, layer_index):\n",
    "        return layer_index == 0\n",
    "\n",
    "    def is_middle_layer(self, layer_index):\n",
    "        return layer_index > 0 and layer_index < len(self.layers)\n",
    "\n",
    "    def is_output_layer(self, layer_index):\n",
    "        return layer_index == len(self.layers)\n",
    "        \n",
    "    def forward_calculate(self, input_values, true_y):\n",
    "        # Прямой проход\n",
    "        if len(self.layers) < 1:\n",
    "            print('Cannot forward calculate, because neural network is empty')\n",
    "            return False\n",
    "        elif len(input_values) < len(self.layers[0]):\n",
    "            print('Cannot forward calculate, not enough input values were given')\n",
    "            return False\n",
    "        else:\n",
    "            for input_neuron, input_value in zip(self.layers[0], input_values):\n",
    "                input_neuron.last_value = input_value\n",
    "            for layer in self.layers:\n",
    "                for neuron in layer:\n",
    "                    neuron.activate()\n",
    "            output_neurons_values = [neuron.last_value for neuron in self.layers[-1]]\n",
    "            predicted_y = \\\n",
    "                sum(output_neurons_values) / len(output_neurons_values)\n",
    "            self.ready_to_back_propagate = True\n",
    "            loss = self.cost_function(true_y, predicted_y)\n",
    "            return true_y, predicted_y, loss\n",
    "    \n",
    "    def backward_propagate(self, true_y, predicted_y):\n",
    "        # Обратный проход\n",
    "        if len(self.layers) < 1:\n",
    "            print('Cannot backward propagate, because neural network is empty')\n",
    "            return False\n",
    "        elif not self.ready_to_back_propagate:\n",
    "            print('Cannot backward propagate, because did not forward calculated yet')\n",
    "            return False\n",
    "        else:\n",
    "            for layer in reversed(self.layers):\n",
    "                anti_gradient = None\n",
    "                if layer == self.layers[-1]:\n",
    "                    # для последнего слоя антиградиент рассчитывается\n",
    "                    # как производная функции потерь:\n",
    "                    anti_gradient = self.cost_function(true_y,\n",
    "                                                       predicted_y,\n",
    "                                                       return_derivative=True)\n",
    "                if not self.backward_propagate_layer(layer, anti_gradient=anti_gradient):\n",
    "                    print('Cannot backward propagate through layer:', self.layers.index(layer))\n",
    "                    return False\n",
    "            self.ready_to_back_propagate = False\n",
    "            if not self.update_weights_and_biases():\n",
    "                print('Cannot update weights')\n",
    "                return False\n",
    "            self.reset_anti_gradients_updated_weights_and_last_values()\n",
    "            return True\n",
    "    \n",
    "    def backward_propagate_layer(self, layer, anti_gradient=None):\n",
    "        # Обратный проход по слою\n",
    "        for neuron in layer:\n",
    "            if not self.backward_propagate_neuron(neuron, anti_gradient=anti_gradient):\n",
    "                print('Cannot backward propagate through neuron:', neuron.name)\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def backward_propagate_neuron(self, neuron, anti_gradient=None):\n",
    "        # Обратный проход по нейрону\n",
    "        if anti_gradient is None:\n",
    "            anti_gradient = neuron.calculate_anti_gradient()\n",
    "        # update weights\n",
    "        for input_connection in neuron.input_connections:\n",
    "            if not self.backward_propagate_input_connection(input_connection,\n",
    "                                                            anti_gradient):\n",
    "                print('Cannot back propagate connection:', input_connection)\n",
    "                return False\n",
    "        # bias update\n",
    "        new_anti_gradient = \\\n",
    "            anti_gradient * \\\n",
    "                neuron.activation_function(neuron.bias, return_derivative=True)\n",
    "        neuron.updated_bias = \\\n",
    "            neuron.bias - self.learning_rate * new_anti_gradient\n",
    "        return True\n",
    "    \n",
    "    def backward_propagate_input_connection(self, connection, anti_gradient):\n",
    "        # Обратный проход по связи\n",
    "        if anti_gradient is None:\n",
    "            print(\"Cannot back propagate, because connection anti-gradient is 'None'\")\n",
    "            return False\n",
    "        weighted_signal = connection.output_neuron.input_connections.get(connection)\n",
    "        if weighted_signal is None:\n",
    "            print(\"Cannot back propagate, because no signal was send \"\n",
    "                  \"through connection:\", connection)\n",
    "            return False\n",
    "        if not self.check_derivative(connection.output_neuron.activation_function,\n",
    "                                     weighted_signal):\n",
    "            print('Derivative caluclation is wrong, check for errors')\n",
    "            return False\n",
    "        new_anti_gradient = \\\n",
    "            anti_gradient * \\\n",
    "                connection.output_neuron.activation_function(\n",
    "                    weighted_signal,\n",
    "                    return_derivative=True\n",
    "                )\n",
    "        connection.updated_weight = \\\n",
    "            connection.weight - self.learning_rate*new_anti_gradient\n",
    "        connection.anti_gradient = new_anti_gradient\n",
    "        return True\n",
    "\n",
    "    def check_derivative (self, activation_function, weighted_signal):\n",
    "        # Численная проверка правильности вычисленной производной\n",
    "        formal_derivative = activation_function(weighted_signal, return_derivative=True)\n",
    "        numeric_deivative = (  activation_function(weighted_signal + self.derivative_delta)   \\\n",
    "                             - activation_function(weighted_signal - self.derivative_delta) ) \\\n",
    "                                                / (self.derivative_delta*2)\n",
    "        if abs(formal_derivative - numeric_deivative) > self.derivative_delta:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def update_weights_and_biases(self):\n",
    "        # Обновляем веса и bias'ы\n",
    "        for layer in self.layers:\n",
    "            for neuron in layer:\n",
    "                for output_connection in neuron.output_connections:\n",
    "                    if output_connection.updated_weight is None:\n",
    "                        print(\"Updated weight is 'None'\")\n",
    "                        return False\n",
    "                    output_connection.weight = output_connection.updated_weight\n",
    "                if neuron.updated_bias is None:\n",
    "                    print(\"Neuron updated bias is 'None'\")\n",
    "                else:\n",
    "                    neuron.bias = neuron.updated_bias\n",
    "        return True\n",
    "    \n",
    "    def reset_anti_gradients_updated_weights_and_last_values(self):\n",
    "        # Сбрасываем временные значения весов, bias'ов и антиградиентов \n",
    "        for layer in self.layers:\n",
    "            for neuron in layer:\n",
    "                neuron.last_value = None\n",
    "                neuron.updated_bias = None\n",
    "                for output_connection in neuron.output_connections:\n",
    "                    output_connection.updated_weight = None\n",
    "                    output_connection.anti_gradient = None\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: разделить на два класса случайные точки с коордиантами (x, y), где [0 < x < 1] и [0 < y < 1].\n",
    "Разделяющая прямая: y = x, т.е. всё что выше – класс '1', всё что ниже – класс '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем данные:\n",
    "def generate_data(count=1000):\n",
    "    data = []\n",
    "    for i in range(count):\n",
    "        x = get_random_number(0, 1)\n",
    "        y = get_random_number(0, 1)\n",
    "        true_class = 1 if y > x else 0\n",
    "        data.append((x, y, true_class)) # [x, y, true_class]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network = FullyConnectedNeuroNetwork()\n",
    "neural_network.add_layer(2, activation_function=sigmoid)\n",
    "neural_network.add_layer(1, activation_function=sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.69696 -->  Loss: 0.69738 -->  Loss: 0.69668 -->  Loss: 0.69617 -->  Loss: 0.69663 -->  Loss: 0.69664 -->  Loss: 0.69721 -->  Loss: 0.69702 -->  Loss: 0.69721 -->  Loss: 0.69641 -->  Loss: 0.69707 -->  Loss: 0.69727 -->  Loss: 0.69724 -->  Loss: 0.69724 -->  Loss: 0.69620 -->  Loss: 0.69710 -->  Loss: 0.69580 -->  Loss: 0.69784 -->  Loss: 0.69721 -->  Loss: 0.69737 -->  "
     ]
    }
   ],
   "source": [
    "for i in range(0, 20):\n",
    "    counter = 0\n",
    "    sum_loss = 0\n",
    "    data = generate_data()\n",
    "    for j in range(len(data)):\n",
    "        input_values = data[j][:-1]\n",
    "        true_class = data[j][-1]\n",
    "        counter += 1\n",
    "        true_class, predicted_class, loss = \\\n",
    "            neural_network.forward_calculate(input_values, true_class)\n",
    "        sum_loss += loss\n",
    "        neural_network.backward_propagate(true_class, predicted_class)\n",
    "    print('Loss: {:.5f}'.format(sum_loss / counter), end=' -->  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network = FullyConnectedNeuroNetwork()\n",
    "neural_network.add_layer(2, activation_function=sigmoid)\n",
    "neural_network.add_layer(4, activation_function=sigmoid)\n",
    "neural_network.add_layer(2, activation_function=sigmoid)\n",
    "neural_network.add_layer(1, activation_function=sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.69332 -->  Loss: 0.69357 -->  Loss: 0.69327 -->  Loss: 0.69432 -->  Loss: 0.69145 -->  Loss: 0.69481 -->  Loss: 0.69283 -->  Loss: 0.69414 -->  Loss: 0.69393 -->  Loss: 0.69347 -->  Loss: 0.69329 -->  Loss: 0.69338 -->  Loss: 0.69399 -->  Loss: 0.69389 -->  Loss: 0.69339 -->  Loss: 0.69399 -->  Loss: 0.69389 -->  Loss: 0.69380 -->  Loss: 0.69382 -->  Loss: 0.69337 -->  "
     ]
    }
   ],
   "source": [
    "for i in range(0, 20):\n",
    "    counter = 0\n",
    "    sum_loss = 0\n",
    "    data = generate_data()\n",
    "    for j in range(len(data)):\n",
    "        input_values = data[j][:-1]\n",
    "        true_class = data[j][-1]\n",
    "        counter += 1\n",
    "        true_class, predicted_class, loss = \\\n",
    "            neural_network.forward_calculate(input_values, true_class)\n",
    "        sum_loss += loss\n",
    "        neural_network.backward_propagate(true_class, predicted_class)\n",
    "    print('Loss: {:.5f}'.format(sum_loss / counter), end=' -->  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network = FullyConnectedNeuroNetwork()\n",
    "neural_network.add_layer(2, activation_function=sigmoid)\n",
    "neural_network.add_layer(8, activation_function=sigmoid)\n",
    "neural_network.add_layer(1, activation_function=sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.72006 -->  Loss: 0.69435 -->  Loss: 0.69401 -->  Loss: 0.69372 -->  Loss: 0.69232 -->  Loss: 0.69389 -->  Loss: 0.69323 -->  Loss: 0.69338 -->  Loss: 0.69271 -->  Loss: 0.69314 -->  Loss: 0.69369 -->  Loss: 0.69375 -->  Loss: 0.69338 -->  Loss: 0.69349 -->  Loss: 0.69237 -->  Loss: 0.69309 -->  Loss: 0.69324 -->  Loss: 0.69355 -->  Loss: 0.69269 -->  Loss: 0.69259 -->  "
     ]
    }
   ],
   "source": [
    "for i in range(0, 20):\n",
    "    counter = 0\n",
    "    sum_loss = 0\n",
    "    data = generate_data()\n",
    "    for j in range(len(data)):\n",
    "        input_values = data[j][:-1]\n",
    "        true_class = data[j][-1]\n",
    "        counter += 1\n",
    "        true_class, predicted_class, loss = \\\n",
    "            neural_network.forward_calculate(input_values, true_class)\n",
    "        sum_loss += loss\n",
    "        neural_network.backward_propagate(true_class, predicted_class)\n",
    "    print('Loss: {:.5f}'.format(sum_loss / counter), end=' -->  ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_y = []\n",
    "# predicted_y = []\n",
    "\n",
    "# data = generate_data(10000)\n",
    "# for each in data:\n",
    "#     true_class, predicted_class, loss = \\\n",
    "#         neural_network.forward_calculate(each[:-1], each[-1])\n",
    "#     neural_network.reset_anti_gradients_updated_weights_and_last_values()\n",
    "#     true_y.append(each[-1])\n",
    "#     predicted_class = \\\n",
    "#         1 if predicted_class >= 0.5 else 0\n",
    "#     predicted_y.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = np.array(true_y)\n",
    "# y_pred = np.array(predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
